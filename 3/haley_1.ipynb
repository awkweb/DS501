{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 3 : Textual analysis of movie reviews\n",
    "\n",
    "** Due Date: April 6, 2016 5:59PM**\n",
    "\n",
    "*------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.conversational-technologies.com/nldemos/nlWordle.GIF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    Helen Hong\n",
    "    Haley Huang\n",
    "    Tom Meagher\n",
    "    Tyler Reese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desired outcome of the case study.**\n",
    "* In this case study we will look at movie reviews from the v2.0 polarity dataset comes from\n",
    "the http://www.cs.cornell.edu/people/pabo/movie-review-data.\n",
    "    * It contains written reviews of movies divided into positive and negative reviews.\n",
    "* As in Case Study 2 idea is to *analyze* the data set, make *conjectures*, support or refute those conjectures with *data*, and *tell a story* about the data!\n",
    "    \n",
    "**Required Readings:** \n",
    "* This case study will be based upon the scikit-learn Python library\n",
    "* We will build upon the turtorial \"Working With Text Data\" which can be found at http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "**Case study assumptions:**\n",
    "* You have access to a python installation\n",
    "\n",
    "**Required Python libraries:**\n",
    "* Numpy (www.numpy.org) (should already be installed from Case Study 2)\n",
    "* Matplotlib (matplotlib.org) (should already be installed from Case Study 2)\n",
    "* Scikit-learn (scikit-learn.org) (avaiable from Enthought Canopy)\n",
    "* You are also welcome to use the Python Natural Language Processing Toolkit (www.nltk.org) (though it is not required).\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 points): Complete Exercise 2: Sentiment Analysis on movie reviews from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assuming that you have downloaded the scikit-learn source code:\n",
    "    * The data cane be downloaded using doc/tutorial/text_analytics/data/movie_reviews/fetch_data.py\n",
    "    * A skeleton for the solution can be found in doc/tutorial/text_analytics/skeletons/exercise_02_sentiment.py\n",
    "    * A completed solution can be found in doc/tutorial/text_analytics/solutions/exercise_02_sentiment.py\n",
    "* **It is ok to use the solution provided in the scikit-learn distribution as a starting place for your work.**\n",
    "\n",
    "### Modify the solution to Exercise 2 so that it can run in this iPython notebook\n",
    "* This will likely involved moving around data files and/or small modifications to the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pa\n",
    "import matplotlib.pylab as py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "dataset = load_files(container_path='text_analytics/txt_sentoken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in training (75%) and testing (25%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting user defined parameters for grid search, exploring different parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (5000, 10000, 30000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (1e-3,0.00001),\n",
    "   # 'clf__fit_prior': (True, False) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Naive Bayes with Grid Search(CV=5), showing running time, best parameter and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1140.933s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1,cv =5)\n",
    "t0 = time()\n",
    "gs_clf = gs_clf.fit(docs_train, y_train)    \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.821\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.001\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gs_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89800000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = gs_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90       246\n",
      "          1       0.91      0.88      0.90       254\n",
      "\n",
      "avg / total       0.90      0.90      0.90       500\n",
      "\n",
      "Precision matrix\n",
      "[[225  21]\n",
      " [ 30 224]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAADzCAYAAACL39McAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113942d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "con1=metrics.confusion_matrix(y_test, predicted)\n",
    "print 'Precision matrix'\n",
    "print con1\n",
    "plt.matshow(con1)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Linear Support vector machine with Grid Search(CV=5), showing running time, best parameter and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf2 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, shuffle= True, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters2 = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (5000, 10000, 30000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (1e-3,0.00001, 0.000001),\n",
    "    #'clf__n_iter': (10, 50, 80) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf2 = GridSearchCV(text_clf2, parameters2, n_jobs=-1)\n",
    "t0 = time()\n",
    "gs_clf2 = gs_clf2.fit(docs_train, y_train)    \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % gs_clf2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters2 = gs_clf2.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters2.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted2 = gs_clf2.predict(docs_test)\n",
    "np.mean(predicted2 == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, predicted2))\n",
    "con2=metrics.confusion_matrix(y_test, predicted2)\n",
    "print 'Precision matrix'\n",
    "print con2\n",
    "plt.matshow(con2)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting Logistic regression with Grid Search(CV=5), showing running time, best parameter and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf3 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='log', penalty='l2',alpha=1e-3, n_iter=5, shuffle= True, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf3 = GridSearchCV(text_clf3, parameters2, n_jobs=-1,cv=5)\n",
    "t0 = time()\n",
    "gs_clf3 = gs_clf3.fit(docs_train, y_train)    \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % gs_clf2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters2 = gs_clf3.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters2.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted3 = gs_clf3.predict(docs_test)\n",
    "np.mean(predicted3 == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, predicted3))\n",
    "con3=metrics.confusion_matrix(y_test, predicted3)\n",
    "print 'Precision matrix'\n",
    "print con3\n",
    "plt.matshow(con3)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (20 points): Explore the scikit-learn TfidVectorizer class\n",
    "\n",
    "**Read the documentation for the TfidVectorizer class at http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html.** \n",
    "* Define the term frequencyâ€“inverse document frequency (TF-IDF) statistic (http://en.wikipedia.org/wiki/Tf%E2%80%93idf will likely help).\n",
    "* Run the TfidVectorizer class on the training data above (docs_train).\n",
    "* Explore the min_df and max_df parameters of TfidVectorizer.  What do they mean? How do they change the features you get?\n",
    "* Explore the ngram_range parameter of TfidVectorizer.  What does it mean? How does it change the features you get? (Note, large values  of ngram_range may take a long time to run!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters in tf-idf Vectorizer:\n",
    "min_df : filter all terms with frequency lower than this value. \n",
    "max-df : filter all terms with frequecy greater than this value, used to filter out stop words.\n",
    "n-gram range: How many n-gram words are to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidfv = TfidfVectorizer()\n",
    "tfidfv = tfidfv.set_params(max_df=0.75, max_features= 5000, use_idf= True, smooth_idf=True, sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the tf-idf vectorizer object on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "vectors = tfidfv.fit_transform(docs_train) \n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf4 = MultinomialNB().fit(vectors, y_train)\n",
    "text_clf4.score(vectors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_test= tfidfv.transform(docs_test)\n",
    "predicted4 = text_clf4.predict(count_test)\n",
    "np.mean(predicted4 == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "## Problem 3 (20 points): Machine learning algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based upon Problem 2 pick some parameters for TfidfVectorizer\n",
    "    * \"fit\" your TfidfVectorizer using docs_train\n",
    "    * Compute \"Xtrain\", a Tf-idf-weighted document-term matrix using the transform function on docs_train\n",
    "    * Compute \"Xtest\", a Tf-idf-weighted document-term matrix using the transform function on docs_test\n",
    "    * Note, be sure to use the same Tf-idf-weighted class (**\"fit\" using docs_train**) to transform **both** docs_test and docs_train\n",
    "* Examine two classifiers provided by scikit-learn \n",
    "    * LinearSVC\n",
    "    * KNeighborsClassifier\n",
    "    * Try a number of different parameter settings for each and judge your performance using a confusion matrix (see Problem 1 for an example).\n",
    "* Does one classifier, or one set of parameters work better?\n",
    "    * Why do you think it might be working better?\n",
    "* For a particular choice of parameters and classifier, look at 2 examples where the prediction was incorrect.\n",
    "    * Can you conjecture on why the classifier made a mistake for this prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Already triedl NB, SVM and logistic regression on Problem1. Here are going to try KNN,PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neareast Neighbour Using the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_knn = TfidfVectorizer()\n",
    "tfidf_knn.set_params(analyzer=\"word\", max_df=0.75, ngram_range=(1, 2), use_idf=True, min_df=0.01, binary=False)\n",
    "knn = KNeighborsClassifier(weights=\"distance\", metric=\"euclidean\")\n",
    "pip_knn = Pipeline([(\"tfidf\", tfidf_knn), (\"lalg\", knn)])\n",
    "parameters3 = [ {\n",
    "                    \"tfidf__norm\":[None, \"l2\"],\n",
    "                    \"lalg__n_neighbors\": range(3, 13),\n",
    "                    } ]\n",
    "GridSearch_knn = GridSearchCV(pip_knn, parameters3,\n",
    "                               n_jobs=-1, verbose=1, cv=5)            \n",
    "GridSearch_knn.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print GridSearch_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean accuracy on validation set = %f\" % GridSearch_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print GridSearch_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted5 = GridSearch_knn.predict(docs_test)\n",
    "np.mean(predicted5 == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con5= metrics.confusion_matrix(predicted5, y_test)\n",
    "print(metrics.classification_report(y_test, predicted5))\n",
    "print np.mean(predicted5== y_test)\n",
    "print 'Precision matrix'\n",
    "print con5\n",
    "plt.matshow(con5)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try PCA ( did not figure out a good way yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2D = PCA(n_components=2).fit_transform(vectors.toarray())\n",
    "py.plot(X2D[y_test==0,0],X2D[y_test==0,1],'r.')\n",
    "py.plot(X2D[y_test==1,0],X2D[y_test==1,1],'g.')\n",
    "#py.plot(X2D[y==2,0],X2D[y==2,1],'b.')\n",
    "import matplotlib.pylab as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you find a two dimensional plot in which the positive and negative reviews are separated?\n",
    "    * This problem is hard since you will likely have thousands of features for review, and you will need to transform these thousands of features into just two numbers (so that you can make a 2D plot).\n",
    "* Note, I was not able to find such a plot myself!\n",
    "    * So, this problem is about **trying** but perhaps **not necessarily succeeding**!\n",
    "* I tried two things, neither of which worked very well.\n",
    "    * I first plotted the length of the review versus the number of features we compute that are in that review\n",
    "    * Second I used Principle Component Analysis on a subset of the features.\n",
    "* Can you do better than I did!?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}